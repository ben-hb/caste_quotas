---
title: "Development without Representation: Replication"
author: "Benjamin Hoffner-Brodsky"
date: "5/15/2020"
header-includes:
  - \usepackage{dcolumn}
  - \usepackage{graphicx}
  - \usepackage{lscape}
  - \usepackage{array}
  - \usepackage{caption}
  - \newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
  - \newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
  - \newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
  - \newcolumntype{P}[1]{>{\raggedright\tabularxbackslash}p{#1}}
bibliography: bibliography.bib
output: bookdown::pdf_document2
abstract: "Jensenius (2015) demonstrates that, between 1971 and 2001, Indian assembly constituencies legally mandated to elect candidates belonging to a Scheduled Caste did not exhibit significantly different development indicators compared with general constituencies. I successfully replicated Jensenius’ results. I propose four alternate models for matching Scheduled Caste (SC) constituencies with general constituencies using a multivariate matching algorithm to mitigate selection bias attributed to treatment assignment and selection bias occurring from unmatched treatment cases. Under two of the four alternate models, I find at least one development indicator with a significant difference across SC and general constituencies. While Jensenius’ hypothesis is largely intact, the variance in results dependent on the selection of model illustrates the need for researchers to optimize and justify choices of matching model parameters and mechanisms." 
link_citations: TRUE
biblio-style: "apalike"
---
\captionsetup[table]{labelformat=empty}
\pagebreak


```{r table_1_setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Note: where possible variable names are preserved from Jensenius' published
# code to allow for easy methodological comparisons

# Each replicated output has 2 code chunks: one setup chunk, with include set to
# FALSE, and one output chunk, with include left to TRUE by default

library(tidyverse)
library(sandwich)
library(apsrtable)
library(lmtest)
library(xtable)
library(Matching)

# Globally stopping xtable() from outputting a package watermark

options(xtable.comment = FALSE)

set.seed(1)

# Use all available cores via parallel computing to speed up matching
# computations

options(mc.cores = parallel::detectCores())

load("replication_files/devDTA.Rdata")

clusterSE <- function(model, data, cluster){

cluster_indices <- model %>% 
  model.matrix() %>% 
  row.names %>% 
  as.numeric()
  
cluster <- data[cluster_indices, cluster] %>% 
  as.factor()

M <- cluster %>%  
  unique() %>% 
  length()
  
N <- length(cluster)

K <- model$rank

dfc <- (M / (M-1)) * ((N-1) / (N-K))

u.clust <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum))

cl.vcov <- dfc * sandwich(model, meat = crossprod(u.clust) / N)

return(cl.vcov)
}

outcomeindex <- c(35, 60, 52, 58, 64, 68, 72, 76, 63, 53, 59, 67, 71, 75, 79)

# The name of the output matrix for table one has been changed from "mymatrix"
# in Jensenius' code, as there were multiple matrices called "mymatrix"

mymatrix1 <- matrix(nrow = length(outcomeindex), ncol = 4)

# Regression for loop begins 

# Iterates over each outcome variable in outcomeindex

for(i in 1:length(outcomeindex)){
  
# Subsets devDTA to only those observations for which the outcome variable of
# interest and the constituency type (Scheduled Caste or General) is known to
# prepare for regressing the outcome variable on the constituency type below
  
devDTAer <- devDTA[complete.cases(devDTA[, outcomeindex[i]], devDTA$AC_type_noST), ]

# Calculates the mean of the outcome variable of interest for each of the
# Scheduled Caste subset and the General Caste subset, respectivelty, rounded to
# 1 decimal, and outputs the General mean into the first column and Scheduled
# Caste mean into the second column of mymatrix

mymatrix1[i, c(1,2)] <- tapply(devDTAer[, outcomeindex[i]], devDTAer$AC_type_noST, 
                                 mean, na.rm = T) %>% 
  round(1)

# Regresses the outome variable of interest on the type of constituency using a
# linear model

myOLS <- lm(devDTAer[, outcomeindex[i]] ~ devDTAer$AC_type_noST)

# Rounds the coefficient of constituency type on the outcome variable of
# interest to 1 decimal, and outputs into the third column of mymatrix

mymatrix1[i, c(3)] <- round(myOLS$coef[2], 1)

# Calculates the p-value using state-level clustered standard errors from
# clusterSE(), estimated separately for each outcome variable, and outputs into
# the fourth column of mymatrix after rounding to 2 decimals. If the p-value is
# less than 0.01, then "<0.01" is outputted instead

mySE <- clusterSE(myOLS, data = devDTAer, cluster = "State_no_2001_old")

mymatrix1[i, c(4)] <- ifelse(coeftest(myOLS, mySE)[2,4] < 0.01, "<0.01", 	
                         round(coeftest(myOLS, mySE)[2, 4] ,2))

# Regression for loop ends
}

# Renames the rows to the name of the outcome variable of interest

row.names(mymatrix1) <- names(devDTA[outcomeindex])

# Renames the columns to the names of the statistics being generated. As the
# model estimated was a binary explanatory linear model, the coefficient of
# constituency type on the outcome variable of interest can similarly be
# interpreted as the difference between the means of the two samples

colnames(mymatrix1) <- c("Mean general", "Mean reserved", "Difference", "P-value")

# Renames the rows again, this time to more readable interpretations of the
# outcome variables of interest. There's no reason to rename twice; the first
# rename was presumably an intermediary step to more easily determine the order
# of rownames

row.names(mymatrix1) <- c("Percentage of SCs", "Literacy rate", " Employment Rate", 
                       "Agricultural laborers", "Electricity in village", 
                       "School in village ","Medical facility in village",
                       "Comm. channel in village", "Literacy gap", " Employment gap", 
                       "Agricultural laborers gap", "Electricity in village gap", 
                       "School in village gap","Medical facility in village gap",
                       "Comm. channel in village gap")
```

```{r figure_1_setup, include = FALSE}

# Instructing R to attach devDTA to the R search path so that variables within
# devDTA can be referenced solely by the column name

attach(devDTA)

# Generating a length 2 vector with first row equal to the mean of the 1971
# literacy rate for individuals who are not members of a Scheduled Caste and
# live in a General constituency and second row equal to the mean of the
# literacy rate under the same constraints but measured in 2001

myplot_gen <- mean(Plit71_nonSC[AC_type_noST == "GEN"], na.rm = T) %>% 
  rbind(mean(Plit_nonSC_7[AC_type_noST == "GEN"], na.rm = T)) %>% 
  as.data.frame() %>% 
  cbind(c(1971, 2001)) %>% 
  cbind(c("gen", "gen"))

names(myplot_gen) <- c("y", "x", "group")
# Generating a length 2 vector with first row equal to the mean of the 1971
# literacy rate for individuals who are not members of a Scheduled Cast and live
# in a Scheduled Cast quota constituency and second row equal to the mean of the
# literacy rate under the same consteaints but measured in 2001

myplot_sc <- mean(Plit71_nonSC[AC_type_noST == "SC"], na.rm = T) %>% 
  rbind(mean(Plit_nonSC_7[AC_type_noST == "SC"], na.rm = T)) %>% 
  as.data.frame() %>% 
  cbind(c(1971, 2001)) %>% 
  cbind(c("sc", "sc"))

names(myplot_sc) <- names(myplot_gen)

# Generating a length 2 vector with first row equal to the mean of the 1971
# literacy rate for individuals who are members of a Scheduled Caste and live in
# a General constituency and second row equal to the mean of the literacy rate
# under the same constraints but measured in 2001

myplot2_gen <- mean(Plit71_SC[AC_type_noST == "GEN"], na.rm = T) %>% 
  rbind(mean(Plit_SC_7[AC_type_noST == "GEN"], na.rm = T)) %>% 
  as.data.frame() %>% 
  cbind(c(1971, 2001)) %>% 
  cbind(c("gen2", "gen2"))

names(myplot2_gen) <- names(myplot_gen)

# Generating a length 2 vector with first row equal to the mean of the 1971
# literacy rate for individuals who are members of a Scheduled Caste and live in
# a Scheduled Caste quote constituency and second row equal to the mean of the
# literacy rate under the same constraints but measured in 2001

myplot2_sc <- mean(Plit71_SC[AC_type_noST == "SC"], na.rm = T) %>% 
  rbind(mean(Plit_SC_7[AC_type_noST == "SC"], na.rm = T)) %>% 
  as.data.frame() %>% 
  cbind(c(1971, 2001)) %>% 
  cbind(c("sc2", "sc2"))

names(myplot2_sc) <- names(myplot_gen)

myplot <- rbind(myplot_gen, myplot_sc) 

myplot2 <- rbind(myplot2_gen, myplot2_sc)

# Prepare dataframe for plotting arrows showing general change

x_gen <- 1971 + 0.02 
x_sc <- 2001 - 0.02

y0_gen <- myplot_gen[1, 1] + 2
y1_gen <- myplot_gen[2, 1] - 2

y0_sc <- myplot_sc[1, 1] + 2
y1_sc <- myplot_sc[2, 1] - 2 

myplot_arrows <- data.frame(x = c(x_gen, x_gen, x_sc, x_sc), 
                            y = c(y0_gen, y1_gen, y0_sc, y1_sc),
                            group = c("gen", "gen", "sc", "sc"))

# Same for myplot2

x_gen_2 <- 1971 + 0.02 
x_sc_2 <- 2001 - 0.02

y0_gen_2 <- myplot2_gen[1, 1] + 2
y1_gen_2 <- myplot2_gen[2, 1] - 2

y0_sc_2 <- myplot2_sc[1, 1] + 2
y1_sc_2 <- myplot2_sc[2, 1] - 2 

myplot2_arrows <- data.frame(x = c(x_gen_2, x_gen_2, x_sc_2, x_sc_2), 
                            y = c(y0_gen_2, y1_gen_2, y0_sc_2, y1_sc_2),
                            group = c("gen", "gen", "sc", "sc"))

# Detaches devDTA from the R search path
  
detach(devDTA)

```

```{r table_2_setup, include = FALSE}
  
# Subsets devDTA to just the observations for which all of the following values
# are known: the percentage of Scheduled Caste individuals in 1971, the state an
# assembly constituency belonged to in 2001, the constituencty type of the
# assembly constituency not including Scheduled Tribes from 1974-2000, the
# Scheduled Caste literacy rate in 1971, and the Scheduled Caste literacy rate
# in 2001

matchdta <- devDTA %>% 
  filter(!is.na(devDTA$SC_percent71_true), 
         !is.na(devDTA$State_no_2001_old), 
         !is.na(devDTA$AC_type_noST),
         !is.na(devDTA$Plit71_SC), 
         !is.na(devDTA$Plit_SC))

# Attaches matchdta to the default R search path 

attach(matchdta)

# Generates a numeric variable which returns 1 if the Assembly Constituency is a
# Scheduled Caste Constituency and 0 otherwise

Tr <- ifelse(AC_type_noST == "SC", 1, 0)

# Generates a new data frame composed of the following variables from matchdta:
# the state an assembly constituency belonged to in 2001, the number of the
# district an Assembly Constituency was in accoring to the 1976 Delimitation
# report, the number of the Parliamentary Constituency an Assembly Constituency
# was part of from 1974-2000, and the percentage of Scheduled Caste individuals
# in 1971

X <- as.data.frame(cbind(as.numeric(State_no_2001_old), 
                         as.numeric(DELIM_district_no), 
                         as.numeric(PC_no_1976), 
                         SC_percent71_true))

# Strict Matching

# Estimates the average treatment effect with literacy rate as the outcome
# variable being matched on the explanatory variables in X for the treatments in
# Tr, which does exact matching for all explanatory variables except for the
# percentage of Scheduled Caste individuals in 1971

# This is done using a multivariate and propensity score matching estimator

# Matching on 2001 literacy rate as the outcome variable, SC/GEN as treatment,
# and matching on state, district, parliamentary constituency, and percentage
# SCs

Matched_norep1 <- Match(Y = Plit, Tr = Tr, X = X, estimand = "ATT", 
                       exact = c(TRUE, TRUE, TRUE, FALSE), 
                     replace = FALSE)

# Evaluate whether or not the match was successful in achieving balance on the
# observed covariates

bal_SC_norep1 <- MatchBalance(Tr ~ SC_percent71_true, match.out = Matched_norep1, nboots = 1000, 
                            data = matchdta)

# Evaluates whether or not the match was successful using a wider array of
# covariates than before

bal.out_norep1 <- MatchBalance(Tr ~ Pop_tot1971 + P_ST71 + Plit71_nonSC + Plit71_SC + 
                                P_W71_nonSC + P_W71_SC + P_al71_nonSC + P_al71_SC, 
                              match.out=Matched_norep1, nboots = 1000, data = matchdta)

# Prepares covariates for professional output

covariates <- cbind(Pop_tot1971, P_ST71, Plit71_nonSC, Plit71_SC, P_W71_nonSC, 
                                  P_W71_SC, P_al71_nonSC, P_al71_SC) %>% 
  as.data.frame()

names(covariates) <- c("Population size", "Percentage of STs", "Literacy rate (non-SCs)", 
                     "Literacy rate (SCs)", "Employment (non-SCs)", "Employment (SCs)", 
                     "Agricultural laborers (non-SCs)", "Agricultural laborers (SCs)")

# Prepares results for future analysis 

treatedDTA1 <- matchdta[Matched_norep1$index.treated, ]
controlDTA1 <- matchdta[Matched_norep1$index.control, ]
treatedDTA1$index.match <- c(1:dim(treatedDTA1)[1])
controlDTA1$index.match <- c(1:dim(controlDTA1)[1])

matched1 <- rbind(treatedDTA1, controlDTA1)

# Caliper Matching

# Runs the same estimation as for Matched_norep1 except with specified calipers,
# or acceptable distances for matching, to specify a tolerance of 0.5 stanard
# deviations for the percentage of Scheduled Caste individuals in 1971

Matched_norep2 <- Match(Y = Plit, Tr = Tr, X = X, estimand = "ATT", 
                       exact = c(TRUE, TRUE, TRUE, FALSE), 
                     replace = FALSE, caliper = c(0, 0, 0, 0.5))

# Evaluate whether or not the match was successful in achieving balance on the
# observed covariates

bal_SC_norep2 <- MatchBalance(Tr ~ SC_percent71_true, match.out = Matched_norep2, nboots = 1000, 
                            data = matchdta)

# Evaluates whether or not the match was successful using a wider array of
# covariates than before

bal.out_norep2 <- MatchBalance(Tr ~ Pop_tot1971 + P_ST71 + Plit71_nonSC + Plit71_SC + 
                                P_W71_nonSC + P_W71_SC + P_al71_nonSC + P_al71_SC, 
                              match.out = Matched_norep2, nboots = 1000, data = matchdta)

# Prepares results for future analysis 

treatedDTA2 <- matchdta[Matched_norep2$index.treated, ]
controlDTA2 <- matchdta[Matched_norep2$index.control, ]
treatedDTA2$index.match <- c(1:dim(treatedDTA2)[1])
controlDTA2$index.match <- c(1:dim(controlDTA2)[1])

matched2 <- rbind(treatedDTA2, controlDTA2)

# Outputs a table with the t and KS p-values before matching, after matching,
# and after matching with caliper

balanceTable2 <- function(covariates, bal.out1, bal.out2){

  cat("\\begin{table}[ht] \n")
  cat(" \\resizebox{\\textwidth}{!}{ \n \\begin{tabular}{lrrrrrr} \\hline \\hline \n")
  cat("Covariate	&\\multicolumn{2}{c}{Before matching}",
    "&\\multicolumn{2}{c}{After matching}", "&\\multicolumn{2}{c}{Matching (caliper)}", "\\", "\\", "\\cline{2-3} \\cline{4-5} \\cline{6-7} \n", sep = "")
  cat("& \\emph{t p}-value &KS \\emph{p}-value &",
    "\\emph{t p}-value &KS \\emph{p}-value &", "\\emph{t p}-value &KS \\emph{p}-value",
    "\\", "\\", "\n", sep = "")
  
  z <- sapply(1:dim(covariates)[2], function(x){
    cat(names(covariates)[x], "&",
    round(bal.out1$BeforeMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out1$BeforeMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out1$BeforeMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
    round(bal.out1$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out1$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out1$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
    round(bal.out2$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out2$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out2$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "\\", "\\", "\n",
      sep = "")
  })
  cat("\\end{tabular}} \\end{table} \n")
}

detach(matchdta)

```

```{r figure_2_setup, include = FALSE}

# Plots the distribution of the percentage of Scheduled Caste members in the
# constituency for both the General and Reserved Constituencies. The first plot
# shows hows this looks before matching, demonstrating that Reserved
# Constituencies tend to have a higher percentage of Scheduled Caste Community
# members than do General Constituencies. The second plot shows how this looks
# after matching, with the two distributions now being much closer but the
# Reserved Constituency distribution still being slightly to the right of the
# General Constituency distribution. The third plot shows this using matching
# with the more precise application of caliper, with a 0.5 standard deviation
# tolerance for matching, which now shows nearly identical distributions, though
# with a tiny right skew still remaining for Reserved Constituencies.

# Preparing to artificially generate legends, as the data is not sufficiently
# tidy to use aesthetic mappings

colors <- c("Reserved" = "red", "General" = "blue")

```

```{r table_3_setup, include = FALSE}

matching_est <- function(matched1, matched2, outcomeindex) {
  

# Generates a new matrix with row number equivalent to the number of outcome
# variables of interest

mymatrix <- matrix(nrow = length(outcomeindex), ncol = 12)

# for loop to run regressions and calculate standard errors begins
# Iterates once for each outcome variable of interest 

for(i in 2:length(outcomeindex)){

# Prepares both matched models for regression 
  
matched1_smaller <- matched1[complete.cases(matched1[outcomeindex[i]], matched1$AC_type_noST), ]
matched2_smaller <- matched2[complete.cases(matched2[outcomeindex[i]], matched2$AC_type_noST), ]

# Regresses outcome variable of interest on type of constituency

mymodel <- lm(matched1_smaller[, outcomeindex[i]] ~ matched1_smaller$AC_type_noST)

# Runs clusterSE() from earlier to calculate clustered standard errors

mySE <- clusterSE(mymodel, data = matched1_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for all matches to the first column to prepare
# for the xtable() call

mymatrix[i, 1] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 2] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 3] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for all matches to the second column to prepare for the
# xtable() call

mymatrix[i, 4] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                         round(coeftest(mymodel, mySE)[2, 4], 2))

# Repeating with caliper matching 

mymodel <- lm(matched2_smaller[, outcomeindex[i]] ~ matched2_smaller$AC_type_noST)

mySE <- clusterSE(mymodel, data = matched2_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for caliper matches to the third column to
# prepare for the xtable() call

mymatrix[i, 5] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 6] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 7] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for caliper matches to the fourth column to prepare for the
# xtable() call

mymatrix[i,8] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                        round(coeftest(mymodel, mySE)[2, 4], 2))

# Adding in bias adjustment

SCpop <- matched2_smaller$SC_pop71_true
mymodel <- lm(matched2_smaller[, outcomeindex[i]] ~ matched2_smaller$AC_type_noST + SCpop)

# Clusters SEs at state level 

mySE <- clusterSE(mymodel, data = matched2_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for bias-adjusted matches to the fifth column
# to prepare for the xtable() call

mymatrix[i, 9] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 10] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 11] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for bias-adjusted matches to the sixth column to prepare for
# the xtable() call

mymatrix[i, 12] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                          round(coeftest(mymodel, mySE)[2, 4], 2))

# regression for loop ends

}	

# Setting the row and column names to prepare for the xtable() call
	
row.names(mymatrix) <- names(devDTA[outcomeindex])
colnames(mymatrix) <- c("Difference", "Conf.int min", "Conf.int max", "P-value", "Difference", 
                        "Conf.int min", "Conf.int max", "P-value", "Difference", "Conf.int min", 
                        "Conf.int max", "P-value")

row.names(mymatrix) <- c("Percentage SCs", "Literacy rate ", "Employment rate ", 
                         "Agricultural laborers", "Electricity in village", "School in village ",
                         "Medical facility in village","Comm. channel in village", "Literacy gap", 
                         "Employment gap", "Agricultural laborers gap", 
                         "Electricity in village gap", "School in village gap",
                         "Medical facility in village gap","Comm. channel in village gap")

# Subsetting matrix that will go on to make the coefficient figure below

figurematrix <- mymatrix[-1, -c(1:4)]

# Subsetting matrix that will be exported through xtable()

articlematrix <- mymatrix[-1, c(1, 4, 5, 8, 9, 12)]

articlematrix_output <- xtable(articlematrix,
                               align = c("L{3cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}"))

return(list(articlematrix_output, figurematrix))

}

estimate_1 <- matching_est(matched1, matched2, outcomeindex)
articlematrix_output <- estimate_1[[1]]
figurematrix <- estimate_1[[2]]

```

```{r figure_3_setup, include = FALSE}

# Tidying data to convert estimate type into a variable to aid in ggplot legend
# design

figurematrix_matching <- figurematrix[, 1:4] %>% 
  cbind(type = "matching",
        coefficient = rownames(figurematrix))

figurematrix_bias <- figurematrix[, 5:8] %>% 
  cbind(type = "bias",
        coefficient = rownames(figurematrix))

figuredf <- figurematrix_matching %>% 
  rbind(figurematrix_bias) %>% 
  data.frame() %>% 
  
# Reordering factor to match Jensenius' y-axis order
  
  mutate(Difference = as.numeric(as.character(Difference)),
         Conf.int.min = as.numeric(as.character(Conf.int.min)),
         Conf.int.max = as.numeric(as.character(Conf.int.max)),
         coefficient = factor(coefficient, levels = c(
           "Literacy rate ", "Employment rate ", "Agricultural laborers", 
           "Electricity in village", "School in village ", "Medical facility in village",
           "Comm. channel in village", "Literacy gap", "Employment gap", "Agricultural laborers gap",
           "Electricity in village gap", "School in village gap", "Medical facility in village gap",
           "Comm. channel in village gap"
         )))

```

```{r table_4_setup, include = FALSE}

# Outputting variables from matched2 into their own vectors for clearer
# interpretation in the forthcoming regressions

# This section explores the interaction effects with the percentage of Scheduled
# Caste individuals in the community, with a particular intent to identify if
# there is an interaction effect between percent SC and the type of constituency

PropSC <- matched2$SC_percent71_true 
educ_lag <- matched2$Plit71_SC
worker_lag <- matched2$P_W71_SC 
agr_lag <- matched2$P_al71_SC
stateFE <- as.factor(matched2$State_no_2001_old)

# In this section two distinct regression models are employed for each outcome
# variable of interest

# Model 1 regresses on the type of constituency, the proportion of Scheduled
# Caste individuals, and the interaction effect of the two

# Model 2 includes all of the explanatory variables from Model 1, in addition to
# the baseline value of the outcome variable of interest and a state fixed
# effect

# Regressing Scheduled Caste literacy rate

# Model 1 

model1lm <- lm(matched2$Plit_SC_7 ~ matched2$AC_type_noST * PropSC)

# Model 2 

model3lm <- lm(matched2$Plit_SC_7 ~ educ_lag + matched2$AC_type_noST * PropSC + stateFE)

# Regressing Scheduled Caste employment rate 

# Model 1 

model4lm <- lm(matched2$P_W_SC ~ matched2$AC_type_noST * PropSC)

# Model 2 

model6lm <- lm(matched2$P_W_SC ~ worker_lag + matched2$AC_type_noST * PropSC + stateFE)

# Regressing Scheduled Caste agricultural labor share 

# Model 1 

model7lm <- lm(matched2$P_al_SC ~ matched2$AC_type_noST * PropSC)

# Model 2 

model9lm <- lm(matched2$P_al_SC ~ agr_lag + matched2$AC_type_noST * PropSC + stateFE)

# Estimating standardized errors clustered at the state level

model1lm$se <- clusterSE(model1lm, data = matched2, cluster = "State_no_2001_old")
model3lm$se <- clusterSE(model3lm, data = matched2, cluster = "State_no_2001_old")
model4lm$se <- clusterSE(model4lm, data = matched2, cluster = "State_no_2001_old")
model6lm$se <- clusterSE(model6lm, data = matched2, cluster = "State_no_2001_old")
model7lm$se <- clusterSE(model7lm, data = matched2, cluster = "State_no_2001_old")
model9lm$se <- clusterSE(model9lm, data = matched2, cluster = "State_no_2001_old")

# Outputting results into apsr table 

table_OLS <- apsrtable(model1lm, model3lm, model4lm, model6lm, model7lm, model9lm, 
                       se = "robust", omitcoef = c(6:19),  
                       coef.names = c("Intercept", "SC reserved", "Percentage SC", 
                                      "SC reserved * Percentage SC", "Literacy SC in 1971", 
                                      "Worker SC in 1971", "Agr. laborer SC in 1971"))

```

```{r table_5_setup, include = FALSE}


# This section explores the possibility that there is no visible effect on net
# development because quota-elected politicians shift resources from high
# Scheduled Caste density areas to low density areas. It does so by attempting
# to predict various development indicators, namely whether or not a village was
# electrified, has a primary school, has a medical facility, and has a
# communication channel, using an interaction model effect with type of
# constituency and proportion of Scheduled Caste individuals

load("replication_files/Vill_AC.RData")

vill_con$VD01_state_id <- as.numeric(as.character(vill_con$VD01_state_id))

# Only using villages that correspond to Assembly Constituencies from the quota
# dataset

vill <- merge(vill_con, matched2[, c(1:2, 28)], by.x = c("VD01_state_id", "VD01_AC_id"), 
              by.y = c("State_number_2001", "AC_no_2001"))

# Preparing variables for regression

PropSC_vill <- (as.numeric(as.character(vill$VD01_sc_p)) / as.numeric(as.character(vill$VD01_t_p)))
states <- as.factor(vill$VD01_state_id)

# Regressing outcome variables of interest on the interaction of type of
# constituency and proportion Scheduled Caste and the state fixed effects

# Electricity

model1glm <- glm(vill$VD01_power_supl ~ vill$AC_type_noST * PropSC_vill + 
                   as.factor(vill$VD01_state_id), family = binomial(link = "logit"))

# Primary School

model2glm <- glm(vill$VD01_educ ~ vill$AC_type_noST * PropSC_vill + 
                   as.factor(vill$VD01_state_id), family = binomial(link = "logit"))

# Medical Facility

model3glm <- glm(vill$VD01_medic ~ vill$AC_type_noST * PropSC_vill +
                   as.factor(vill$VD01_state_id), family = binomial(link = "logit"))

# Communication Channel

model4glm <- glm(vill$VD01_comm ~ vill$AC_type_noST * PropSC_vill +
                   as.factor(vill$VD01_state_id), family = binomial(link = "logit"))

# Calculating standard errors clustered at the state level 

cluster <- "VD01_state_id"

model1glm$se <- clusterSE(model1glm, data = vill, cluster = cluster)
model2glm$se <- clusterSE(model2glm, data = vill, cluster = cluster)
model3glm$se <- clusterSE(model3glm, data = vill, cluster = cluster)
model4glm$se <- clusterSE(model4glm, data = vill, cluster = cluster)

# Outputting results into apsr table 

table_logit <- apsrtable(model1glm, model2glm, model3glm, model4glm, se = "both", 
                         stars = 1, omitcoef = c(4:19), 
                         coef.names = c("Intercept", "SC reserved", "Proportion SC", 
                                        "SC reserved * Proportion SC"))
```

```{r extension_norep_caliper, include = FALSE}

attach(matchdta)

# Optimal caliper calculation 

sds <- matchdta %>% 
  group_by(AC_type_1976) %>% 
  summarize(sd = sd(SC_percent71_true))

sd_treated <- sds[[2, 2]]
sd_untreated <- sds[[1, 2]]

sd <- ((sd_treated^2 + sd_untreated^2) / 2) ^ 0.5

optimal_caliper <- 0.2 * sd

# Matching using optimal caliper, without replacement 

Matched_norep_caliper <- Match(Y = Plit, Tr = Tr, X = X, estimand = "ATT", 
                       exact = c(TRUE, TRUE, TRUE, FALSE), 
                     replace = FALSE, caliper = c(0, 0, 0, optimal_caliper))

# Evaluate whether or not the match was successful in achieving balance on the
# observed covariates

bal_SC_norep_caliper <- MatchBalance(Tr ~ SC_percent71_true, match.out = Matched_norep_caliper, 
                                     nboots = 1000, data = matchdta)

# Evaluates whether or not the match was successful using a wider array of
# covariates than before

bal.out_norep_caliper <- MatchBalance(Tr ~ Pop_tot1971 + P_ST71 + Plit71_nonSC + Plit71_SC + 
                                P_W71_nonSC + P_W71_SC + P_al71_nonSC + P_al71_SC, 
                              match.out = Matched_norep_caliper, nboots = 1000, data = matchdta)

# Prepares results for future analysis 

treatedDTA3 <- matchdta[Matched_norep_caliper$index.treated, ]
controlDTA3 <- matchdta[Matched_norep_caliper$index.control, ]
treatedDTA3$index.match <- c(1:dim(treatedDTA3)[1])
controlDTA3$index.match <- c(1:dim(controlDTA3)[1])

matched3 <- rbind(treatedDTA3, controlDTA3)

detach(matchdta)

```

```{r extension_rep_sub, include = FALSE}

attach(matchdta)

# Matching using suboptimal caliper, with replacement 

Matched_rep <- Match(Y = Plit, Tr = Tr, X = X, estimand = "ATT", 
                       exact = c(TRUE, TRUE, TRUE, FALSE), 
                     replace = TRUE)

# Evaluate whether or not the match was successful in achieving balance on the
# observed covariates

bal_SC_rep <- MatchBalance(Tr ~ SC_percent71_true, match.out = Matched_rep, nboots = 1000, 
                            data = matchdta)

# Evaluates whether or not the match was successful using a wider array of
# covariates than before

bal.out_rep <- MatchBalance(Tr ~ Pop_tot1971 + P_ST71 + Plit71_nonSC + Plit71_SC + 
                                P_W71_nonSC + P_W71_SC + P_al71_nonSC + P_al71_SC, 
                              match.out = Matched_rep, nboots = 1000, data = matchdta)

# Prepares results for future analysis 

treatedDTA4 <- matchdta[Matched_rep$index.treated, ]
controlDTA4 <- matchdta[Matched_rep$index.control, ]
treatedDTA4$index.match <- c(1:dim(treatedDTA4)[1])
controlDTA4$index.match <- c(1:dim(controlDTA4)[1])

matched4 <- rbind(treatedDTA4, controlDTA4)

# With suboptimal caliper 

Matched_rep_sub <- Match(Y = Plit, Tr = Tr, X = X, estimand = "ATT", 
                       exact = c(TRUE, TRUE, TRUE, FALSE), 
                     replace = TRUE, caliper = c(0, 0, 0, 0.5))

# Evaluate whether or not the match was successful in achieving balance on the
# observed covariates

bal_SC_rep_sub <- MatchBalance(Tr ~ SC_percent71_true, match.out = Matched_rep_sub, 
                                     nboots = 1000, data = matchdta)

# Evaluates whether or not the match was successful using a wider array of
# covariates than before

bal.out_rep_sub <- MatchBalance(Tr ~ Pop_tot1971 + P_ST71 + Plit71_nonSC + Plit71_SC + 
                                P_W71_nonSC + P_W71_SC + P_al71_nonSC + P_al71_SC, 
                              match.out = Matched_rep_sub, nboots = 1000, data = matchdta)

# Prepares results for future analysis 

treatedDTA5 <- matchdta[Matched_rep_sub$index.treated, ]
controlDTA5 <- matchdta[Matched_rep_sub$index.control, ]
treatedDTA5$index.match <- c(1:dim(treatedDTA5)[1])
controlDTA5$index.match <- c(1:dim(controlDTA5)[1])

matched5 <- rbind(treatedDTA5, controlDTA5)

detach(matchdta)

```

```{r extension_rep_caliper, include = FALSE}

attach(matchdta)

# Matching using optimal caliper, with replacement 

Matched_rep_caliper <- Match(Y = Plit, Tr = Tr, X = X, estimand = "ATT", 
                       exact = c(TRUE, TRUE, TRUE, FALSE), 
                     replace = TRUE, caliper = c(0, 0, 0, optimal_caliper))

# Evaluate whether or not the match was successful in achieving balance on the
# observed covariates

bal_SC_rep_caliper <- MatchBalance(Tr ~ SC_percent71_true, match.out = Matched_rep_caliper, 
                                     nboots = 1000, data = matchdta)

# Evaluates whether or not the match was successful using a wider array of
# covariates than before

bal.out_rep_caliper <- MatchBalance(Tr ~ Pop_tot1971 + P_ST71 + Plit71_nonSC + Plit71_SC + 
                                P_W71_nonSC + P_W71_SC + P_al71_nonSC + P_al71_SC, 
                              match.out = Matched_rep_caliper, nboots = 1000, data = matchdta)

# Prepares results for future analysis 

treatedDTA6 <- matchdta[Matched_rep_caliper$index.treated, ]
controlDTA6 <- matchdta[Matched_rep_caliper$index.control, ]
treatedDTA6$index.match <- c(1:dim(treatedDTA6)[1])
controlDTA6$index.match <- c(1:dim(controlDTA6)[1])

matched6 <- rbind(treatedDTA6, controlDTA6)

detach(matchdta)

```

```{r extension_table_4_setup, include = FALSE}

# Setting up dataframe to compare number of drops across matching models 

# Order: No caliper, 0.5 caliper, 0.2 * sd caliper 

rep_drops <- c(Matched_rep$ndrops, Matched_rep_sub$ndrops, Matched_rep_caliper$ndrops)

norep_drops <- c(Matched_norep1$ndrops, Matched_norep2$ndrops, Matched_norep_caliper$ndrops)

drops <- data.frame(norep_drops, rep_drops)

rownames(drops) <- c("No caliper", "0.5 caliper", "0.2 * sd caliper")

names(drops) <- c("Without Replacement", "With Replacement")

drops_output <- xtable(drops, digits = 0)

```

```{r extension_table_5_setup, include = FALSE}

balanceTable6 <- function(covariates, bal.out_norep1, 
                          bal.out_rep, bal.out_norep2, 
                          bal.out_rep_sub, bal.out_norep_caliper, 
                          bal.out_rep_caliper){

  cat("\\begin{table}[ht] \n")
  cat(" \\resizebox{\\textwidth}{!}{ \n \\begin{tabular}{lrr|rr|rr|rr|rr|rr|rr} \\hline \\hline \n")
  cat("Covariate	&\\multicolumn{2}{c}{Before matching}",
    "&\\multicolumn{2}{c}{Model 1}", "&\\multicolumn{2}{c}{Model 2}", 
    "&\\multicolumn{2}{c}{Model 3}", "&\\multicolumn{2}{c}{Model 4}",
    "&\\multicolumn{2}{c}{Model 5}", "&\\multicolumn{2}{c}{Model 6}",
    "\\", "\\", "\\cline{2-3} \\cline{4-5} \\cline{6-7} \\cline{8-9} \\cline{10-11} \\cline{12-13} 
    \\cline{14-15} \n", sep = "")
  cat("& \\emph{t p}-value &KS \\emph{p}-value &",
    "\\emph{t} &KS &", "\\emph{t} &KS &",
    "\\emph{t} &KS &", "\\emph{t} &KS &",
    "\\emph{t} &KS &", "\\emph{t} &KS",
    "\\", "\\", "\n", sep = "")
  
  z <- sapply(1:dim(covariates)[2], function(x){
    cat(names(covariates)[x], "&",
# Before matching
    round(bal.out_norep1$BeforeMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_norep1$BeforeMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_norep1$BeforeMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
# No Rep 
    round(bal.out_norep1$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_norep1$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_norep1$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
# Rep
    round(bal.out_rep$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_rep$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_rep$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
# No Rep 0.5
    round(bal.out_norep2$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_norep2$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_norep2$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
# Rep 0.5
    round(bal.out_rep_sub$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_rep_sub$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_rep_sub$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
# No Rep 0.2sd
    round(bal.out_norep_caliper$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_norep_caliper$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_norep_caliper$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "&",
# Rep 0.2sd
    round(bal.out_rep_caliper$AfterMatching[[x]]$tt$p.value,2), "&",
    ifelse(is.null(bal.out_rep_caliper$AfterMatching[[x]]$ks$ks.boot.pvalue) == 0,
      round(bal.out_rep_caliper$AfterMatching[[x]]$ks$ks.boot.pvalue,2), "---"), "\\", "\\", "\n",
      sep = "")
  })
  
  ks_ps_before <- data.frame(tt = length(covariates), ks = length(covariates))
  ks_ps_norep1 <- data.frame(tt = length(covariates), ks = length(covariates))
  ks_ps_rep <- data.frame(tt = length(covariates), ks = length(covariates))
  ks_ps_norep2 <- data.frame(tt = length(covariates), ks = length(covariates))
  ks_ps_rep_sub <- data.frame(tt = length(covariates), ks = length(covariates))
  ks_ps_norep_caliper <- data.frame(tt = length(covariates), ks = length(covariates))
  ks_ps_rep_caliper <- data.frame(tt = length(covariates), ks = length(covariates))

  for (i in 1:length(covariates)) {
    ks_ps_before[i, 1] <- bal.out_norep1$BeforeMatching[[i]]$tt$p.value
    ks_ps_before[i, 2] <- bal.out_norep1$BeforeMatching[[i]]$ks$ks.boot.pvalue
    ks_ps_norep1[i, 1] <- bal.out_norep1$AfterMatching[[i]]$tt$p.value
    ks_ps_norep1[i, 2] <- bal.out_norep1$AfterMatching[[i]]$ks$ks.boot.pvalue
    ks_ps_rep[i, 1] <- bal.out_rep$AfterMatching[[i]]$tt$p.value
    ks_ps_rep[i, 2] <- bal.out_rep$AfterMatching[[i]]$ks$ks.boot.pvalue
    ks_ps_norep2[i, 1] <- bal.out_norep2$AfterMatching[[i]]$tt$p.value
    ks_ps_norep2[i, 2] <- bal.out_norep2$AfterMatching[[i]]$ks$ks.boot.pvalue
    ks_ps_rep_sub[i, 1] <- bal.out_rep_sub$AfterMatching[[i]]$tt$p.value
    ks_ps_rep_sub[i, 2] <- bal.out_rep_sub$AfterMatching[[i]]$ks$ks.boot.pvalue
    ks_ps_norep_caliper[i, 1] <- bal.out_norep_caliper$AfterMatching[[i]]$tt$p.value
    ks_ps_norep_caliper[i, 2] <- bal.out_norep_caliper$AfterMatching[[i]]$ks$ks.boot.pvalue
    ks_ps_rep_caliper[i, 1] <- bal.out_rep_caliper$AfterMatching[[i]]$tt$p.value
    ks_ps_rep_caliper[i, 2] <- bal.out_rep_caliper$AfterMatching[[i]]$ks$ks.boot.pvalue
  }
  
  cat("\\hline \n")
  cat("Mean", round(mean(ks_ps_before[, 1]), 2), round(mean(ks_ps_before[, 2]), 2), 
      round(mean(ks_ps_norep1[, 1]), 2), round(mean(ks_ps_norep1[, 2]), 2),
      round(mean(ks_ps_rep[, 1]), 2), round(mean(ks_ps_rep[, 2]), 2),
      round(mean(ks_ps_norep2[, 1]), 2), round(mean(ks_ps_norep2[, 2]), 2),
      round(mean(ks_ps_rep_sub[, 1]), 2), round(mean(ks_ps_rep_sub[, 2]), 2),
      round(mean(ks_ps_norep_caliper[, 1]), 2), round(mean(ks_ps_norep_caliper[, 2]), 2),
      round(mean(ks_ps_rep_caliper[, 1]), 2), round(mean(ks_ps_rep_caliper[, 2]), 2), sep = "&")
  cat("\\", "\\", "\n", sep = "")
  cat("Median", round(median(ks_ps_before[, 1]), 2), round(median(ks_ps_before[, 2]), 2), 
      round(median(ks_ps_norep1[, 1]), 2), round(median(ks_ps_norep1[, 2]), 2),
      round(median(ks_ps_rep[, 1]), 2), round(median(ks_ps_rep[, 2]), 2),
      round(median(ks_ps_norep2[, 1]), 2), round(median(ks_ps_norep2[, 2]), 2),
      round(median(ks_ps_rep_sub[, 1]), 2), round(median(ks_ps_rep_sub[, 2]), 2),
      round(median(ks_ps_norep_caliper[, 1]), 2), round(median(ks_ps_norep_caliper[, 2]), 2),
      round(median(ks_ps_rep_caliper[, 1]), 2), round(median(ks_ps_rep_caliper[, 2]), 2), sep = "&")  
  cat("\\end{tabular}} \\end{table} \n")
}

```

```{r extension_table_6_setup, include = FALSE}

# Replicates Jensenius table 3 for 2 models: replacement without caliper and
# replacement with 0.5 caliper

# Generates a new matrix with row number equivalent to the number of outcome
# variables of interest

mymatrix <- matrix(nrow = length(outcomeindex), ncol = 12)

# for loop to run regressions and calculate standard errors begins
# Iterates once for each outcome variable of interest 

for(i in 2:length(outcomeindex)){

# Prepares both matched models for regression 
  
matched4_smaller <- matched4[complete.cases(matched4[outcomeindex[i]], matched4$AC_type_noST), ]
matched5_smaller <- matched5[complete.cases(matched5[outcomeindex[i]], matched5$AC_type_noST), ]

# Regresses outcome variable of interest on type of constituency

mymodel <- lm(matched4_smaller[, outcomeindex[i]] ~ matched4_smaller$AC_type_noST)

# Runs clusterSE() from earlier to calculate clustered standard errors

mySE <- clusterSE(mymodel, data = matched4_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for all matches to the first column to prepare
# for the xtable() call

mymatrix[i, 1] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 2] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 3] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for all matches to the second column to prepare for the
# xtable() call

mymatrix[i, 4] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                         round(coeftest(mymodel, mySE)[2, 4], 2))

# Repeating with caliper matching 

mymodel <- lm(matched5_smaller[, outcomeindex[i]] ~ matched5_smaller$AC_type_noST)

mySE <- clusterSE(mymodel, data = matched5_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for caliper matches to the third column to
# prepare for the xtable() call

mymatrix[i, 5] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 6] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 7] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for caliper matches to the fourth column to prepare for the
# xtable() call

mymatrix[i,8] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                        round(coeftest(mymodel, mySE)[2, 4], 2))

# Adding in bias adjustment

SCpop <- matched5_smaller$SC_pop71_true
mymodel <- lm(matched5_smaller[, outcomeindex[i]] ~ matched5_smaller$AC_type_noST + SCpop)

# Clusters SEs at state level 

mySE <- clusterSE(mymodel, data = matched5_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for bias-adjusted matches to the fifth column
# to prepare for the xtable() call

mymatrix[i, 9] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 10] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 11] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for bias-adjusted matches to the sixth column to prepare for
# the xtable() call

mymatrix[i, 12] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                          round(coeftest(mymodel, mySE)[2, 4], 2))

# regression for loop ends

}	

# Setting the row and column names to prepare for the xtable() call
	
row.names(mymatrix) <- names(devDTA[outcomeindex])
colnames(mymatrix) <- c("Difference", "Conf.int min", "Conf.int max", "P-value", "Difference", 
                        "Conf.int min", "Conf.int max", "P-value", "Difference", "Conf.int min", 
                        "Conf.int max", "P-value")

row.names(mymatrix) <- c("Percentage SCs", "Literacy rate ", "Employment rate ", 
                         "Agricultural laborers", "Electricity in village", "School in village ",
                         "Medical facility in village","Comm. channel in village", "Literacy gap", 
                         "Employment gap", "Agricultural laborers gap", 
                         "Electricity in village gap", "School in village gap",
                         "Medical facility in village gap","Comm. channel in village gap")

# Subsetting matrix that will go on to make the coefficient figure below

figurematrix_rep <- mymatrix[-1, -c(1:4)]

# Subsetting matrix that will be exported through xtable()

articlematrix_rep <- mymatrix[-1, c(1, 4, 5, 8, 9, 12)]

articlematrix_output_rep <- xtable(articlematrix_rep,
                                   align = c("L{3cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}"))

```

```{r extension_table_7_setup, include = FALSE}

# Replicates Jensenius table 3 for 2 models: replacement with optimal caliper
# and no replacement with optimal caliper

# Generates a new matrix with row number equivalent to the number of outcome
# variables of interest

mymatrix <- matrix(nrow = length(outcomeindex), ncol = 12)

# for loop to run regressions and calculate standard errors begins
# Iterates once for each outcome variable of interest 

for(i in 2:length(outcomeindex)){

# Prepares both matched models for regression 
  
matched6_smaller <- matched6[complete.cases(matched6[outcomeindex[i]], matched6$AC_type_noST), ]
matched3_smaller <- matched3[complete.cases(matched3[outcomeindex[i]], matched3$AC_type_noST), ]

# Regresses outcome variable of interest on type of constituency

mymodel <- lm(matched6_smaller[, outcomeindex[i]] ~ matched6_smaller$AC_type_noST)

# Runs clusterSE() from earlier to calculate clustered standard errors

mySE <- clusterSE(mymodel, data = matched6_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for all matches to the first column to prepare
# for the xtable() call

mymatrix[i, 1] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 2] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 3] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for all matches to the second column to prepare for the
# xtable() call

mymatrix[i, 4] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                         round(coeftest(mymodel, mySE)[2, 4], 2))

# Repeating with caliper matching 

mymodel <- lm(matched3_smaller[, outcomeindex[i]] ~ matched3_smaller$AC_type_noST)

mySE <- clusterSE(mymodel, data = matched3_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for caliper matches to the third column to
# prepare for the xtable() call

mymatrix[i, 5] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 6] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 7] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for caliper matches to the fourth column to prepare for the
# xtable() call

mymatrix[i,8] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                        round(coeftest(mymodel, mySE)[2, 4], 2))

# Adding in bias adjustment

SCpop <- matched3_smaller$SC_pop71_true
mymodel <- lm(matched3_smaller[, outcomeindex[i]] ~ matched3_smaller$AC_type_noST + SCpop)

# Clusters SEs at state level 

mySE <- clusterSE(mymodel, data = matched3_smaller, cluster = "State_no_2001_old")

# Outputs difference coefficient for bias-adjusted matches to the fifth column
# to prepare for the xtable() call

mymatrix[i, 9] <- round(mymodel$coef[2], 2)

# Intermediary steps - will be cleared before xtable()

mymatrix[i, 10] <- round(mymodel$coef[2] + qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)
mymatrix[i, 11] <- round(mymodel$coef[2] - qnorm(.975) * coeftest(mymodel, mySE)[2, 2], 2)

# Outputs p-values for bias-adjusted matches to the sixth column to prepare for
# the xtable() call

mymatrix[i, 12] <- ifelse(coeftest(mymodel, mySE)[2, 4] < 0.01, "<0.01", 
                          round(coeftest(mymodel, mySE)[2, 4], 2))

# regression for loop ends

}	

# Setting the row and column names to prepare for the xtable() call
	
row.names(mymatrix) <- names(devDTA[outcomeindex])
colnames(mymatrix) <- c("Difference", "Conf.int min", "Conf.int max", "P-value", "Difference", 
                        "Conf.int min", "Conf.int max", "P-value", "Difference", "Conf.int min", 
                        "Conf.int max", "P-value")

row.names(mymatrix) <- c("Percentage SCs", "Literacy rate ", "Employment rate ", 
                         "Agricultural laborers", "Electricity in village", "School in village ",
                         "Medical facility in village","Comm. channel in village", "Literacy gap", 
                         "Employment gap", "Agricultural laborers gap", 
                         "Electricity in village gap", "School in village gap",
                         "Medical facility in village gap","Comm. channel in village gap")

# Subsetting matrix that will go on to make the coefficient figure below

figurematrix_cal <- mymatrix[-1, -c(1:4)]

# Subsetting matrix that will be exported through xtable()

articlematrix_cal <- mymatrix[-1, c(1, 4, 5, 8, 9, 12)]

articlematrix_output_cal <- xtable(articlematrix_cal,
                                   align = c("L{3cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}", "R{1.2cm}"))

```


## Introduction

  Since 1950, the Indian Parliament and India's state assemblies have guaranteed a minimum number of seats to Scheduled Castes (SCs). Ensuring ascriptive representation for the 16% of Indian citizens who belong to SCs was intended, in part, as a means to equitably allocate resources along caste lines [@jensenius2015development]. To implement SC quotas, the Government of India (GoI) non-randomly selected constituencies in which only SC members can run for office, though all members of the constituency are allowed to vote. As mandated in the Delimitation Act of 1972, the quotas were generally assigned to the constituency with the largest proportion of SCs in an eligible district and prevented multiple contiguous constituencies from receiving quotas. 

Jensenius forms pairs of reserved and non-reserved constituencies that fall within the same state, district, and parliamentary constituency. As there are 2,409 general constituencies and only 483 reserved constituencies in the dataset, Jensenius pairs treatment cases with the non-treatment case that is most similar in proportion of SCs, without replacement. In the first matching model, all pairs satisfying geographic requirements are preserved, while in the second model a caliper is applied, such that only pairs for which the difference between the proportion of SCs in the treatment and non-treatment case is less than or equal to 0.5 standard deviations. Jensenius uses a constituency-level dataset of 3,134 state assembly constituencies from the 15 largest Indian states with development data from 1971 and 2001. She finds a null constituency-level effect on overall development, redistribution to SCs, literacy rates, SC employment patterns, and village amenities. 

I successfully replicated Jensenius’ results and failed to reject the null hypothesis for a difference in the means of overall development, redistribution to SCs, literacy rates, SC employment patterns, and village amenities. I was able to replicate all tables and figures in @jensenius2015development without discrepancy. I accessed the replication materials from Jensenius’ personal website, which includes all data required for replication, a codebook for the dataset, and the R code necessary to replicate the majority of Jensenius’ results.^[All [data and replication materials](https://www.openicpsr.org/openicpsr/project/113613/version/V1/view) were kindly made public by [Francesca R. Jensenius](https://www.francesca.no), Professor of Political Science at the University of Oslo and Senior Research Fellow at the Norwegian Institute of International Affairs.] I used R for replication and analysis [@R]. 

I examine the robustness @leamer1983reporting of Jensenius’ results relative to the construct of the matching model by proposing two changes to the matching process. First, I match constituencies with replacement, allowing for multiple treatment cases to be paired to the same non-treatment case if doing so would decrease the difference in proportion SCs across the two constituencies. Matching with replacement makes pairs more similar across pre-treatment covariates, eliminates the significance of constituency ordering, and, critically, decreases the number of unmatched treatment cases. Leaving all other aspects of Jensenius’ analysis unchanged, allowing for replacement in the matching method decreases the number of unmatched treatment cases by 20% in the closest match model and by 6.9% in the caliper model. In two of the models matched with replacement, I find a difference in mean development indicators across the two groups that is significant at a 5% level. 

Second, I apply the recommendation coming out of @wang2013optimal's Monte Carlo simulations to optimally select a caliper value of 1.62. In-line with the recommendation of @rosenbaum1985constructing a larger caliper value ameliorates the selection bias created by the systematic differences between cases which are able to be matched and those which are not. Holding all other parameters unchanged, increasing the caliper value from 0.5 to 1.62 decreases the number of unmatched treatment cases by 66% while increasing the median p-values for the difference between matched groups, indicating that the matched groups were also statistically more similar. 

## Literature Review

  SCs have faced ritual discrimination and social exclusion in South Asia since well before the existence of India as a nation [@galanter1984competing]. Traditionally viewed as ‘untouchable’, SCs occupy the lowest rung on India’s social leader and have been systematically excluded from positions of power and social influence through the caste system [@thorat2012has]. Following India’s independence from Great Britain in 1947, the founding members of the GoI wrote SC protections into India’s constitution. SC electoral quotas followed many years of debate and negotiation about the appropriate mechanism to grant constitutional rights to representation to SC communities while attempting to bridge, rather than polarize, the divide. 

The resulting quota system implemented through the Delimitation Act of 1972 signified a compromise, in which electoral slots were reserved for SC members while still necessitating that SC politicians be elected by non-SC members in their constituency. Dr. Bhim Rao Ambedkar, the renowned SC leader and quota lobbyist, notoriously viewed the Delimitation Act of 1972 as a failure. He has commented that “the result is that the legislator of the minority elected to the reserved seat instead of being a champion of the minority is really a slave of the majority” [@jensenius2017social].

Other researchers have probed the effects of other forms of SC quotas. @dunning2013ethnic analyzed village-level SC electoral quotas and found no evidence of SC politicians reallocating resources to SC individuals in their constituency. @pande2003can explored the state assembly quotas and found no changes in spending habits at a state level using a regression discontinuity design. Yet no other researchers prior to or after Jensenius have delved into the effects of state assembly quotas on constituency-level development indicators or resource allocation.

## Replication

  @jensenius2015development stands alone both in its treatment of the constituency-level effects of state assembly quotas and its application of multivariate pre-treatment covariate matching to estimate the average treatment effect on the treated (ATT). To best mitigate treatment selection bias, Jensenius matches treated and non-treated cases only on the pre-treatment variables that government officials in 1972 would have considered. After matching cases, she then clusters standard errors for the difference in development indicator means at the state, district, and parliamentary constituency levels. Under all three calculations, she fails to find a significant difference at the 5% level in development indicators across the treated and untreated groups, indicating a null ATT. 

To operationalize the metric of development, Jensenius considers individual-level indicators with readily available data that a motivated politician could reasonably impact. Consequently, she focuses on literacy rates, employment, and agricultural labor. 

Jensenius also considers village-level development indicators, taking advantage of the overlap between assembly constituencies and villages. To measure village development, she evaluates the availability of electricity, schools, medical facilities, and communication channels in villages, with increases corresponding to a higher level of village development. In all of these indicators, Jensenius finds no significant ATT. 

## Extension

  @leamer1983reporting cautions that the flexibility economics researchers have in selecting econometric models, combined with the tendency of economics journals to select for certain categories of outcomes, can result in an equilibrium in which an apparently robust result should be expected to be a result of model selection rather than underlying statistical truth. They recommend that “researchers be given the task of identifying interesting families of alternative models and be expected to summarize the range of inferences which are implied by each of the families”. It is in the spirit of expanding the families of alternative models that I propose two alterations to @jensenius2015development’s, the combinations of which result in four alternate models to consider. Results from these alternate models consistent with Jensenius’ results would render her conclusions more robust to small changes in econometric model choices, while divergent results would necessitate further exploration to determine the most appropriate choice of models. 

The first modification I propose to @jensenius2015development’s matching methodology is matching with replacement. Three advantages of matching with replacement over matching without replacement motivate this amendment. 

First, sampling without order is sensitive to changes in the order of both treated and non-treated cases. When sampling without replacement, there may be multiple non-treated cases that could be assigned to the same treated case. In @Matching, the R package Jensenius uses for creating pairs and assessing covariate balance, the potential for multiple non-treatment units to be assigned to the same treatment unit is handled by pairing whichever non-treatment unit is ordinally first. Given that there is no ‘correct’ ordering of observations, and that differences in order will correspond to differences in regression coefficients and significance tests, matching without replacement renders the analysis vulnerable both to randomness and to @leamer1983reporting’s concerns regarding researcher discretion. Sampling with replacement comprehensively resolves this issue. When sampling with replacement, multiple non-treatment units can be assigned to the same treatment unit, negating the role of order on groupings, minimizing variance, and avoiding researcher selection bias. 

Second, matching with replacement results in closer matches on inexact pretreatment covariates. Under sampling without replacement, a non-treatment unit may be assigned to the 2nd, 3rd, or 4th closest treatment unit, rather than the 1st closest, because the closest was already paired. Smaller differences in pretreatment covariates means that treated and non-treated units become more directly comparable and the effect of selection bias is minimized. 

Third, matching with replacement decreases the number of unmatched units. When matching without replacement, there will be some units that have an appropriate match in the dataset but are dropped because the only appropriate match/es were already paired. Under matching with replacement, those same units need not be dropped. Dropped units have an outsized negative effect on bias because they are excluded as a function of pre-treatment covariate values. As @rosenbaum1985constructing states: “Discarding treated [cases] in this way can lead to serious biases, since the unmatched treated [cases] differ systematically from the matched treated children”. Holding all else constant, matching with replacement decreases the number of unmatched treatment cases by 20% in the closest match model and by 6.9% in the caliper model.

Matching without replacement is not without drawbacks. Principally, replacing units decreases the effective sample size (ESS) because fewer observations are responsible for explaining a large proportion of the data. Yet this limitation is mitigated by the strict regional matching, with prevents a small number of units from being matched with too large a proportion of the data. 

The second modification I propose is the modification of the caliper value used as the maximum standardized distance in proportion of SCs between matched units. @jensenius2015development employs a 0.5 standard deviation caliper, a critical parameter choice which is not justified in the paper. There is no obviously correct choice of caliper values, as a larger caliper value preserves a large proportion of cases, while a smaller caliper value results in treatment and control groups with more similar pre-treatment covariates, both of which are desirable elements to minimize bias. 

To assess the tradeoff, I apply Wang et al. (2013)’s methodology to select a caliper value of 1.62 standard deviations. The increased caliper value decreases the number of unmatched treatment cases by 66% while increasing the median p-values for the difference between matched groups, indicating that the matched groups were statistically more similar, likely because of the decrease in dropped units and corresponding increase in ESS. 

Table 1 shows the number of dropped unmatched units under each matching model. A larger number indicates a greater danger of selection bias, as units are systematically dropped based on pre-treatment covariates. Predictably, matching with replacement and without a caliper yields the lowest number of dropped units, 28. The most severe results comes from Jensenius (2015)’s model of matching without replacement and with a 0.5 standard deviation caliper which drops 159 units, or 32.9% of all treated units. Though insufficient evidence to be conclusive, the lower number of dropped units under the proposed alternate models could indicate an appropriate fit. 

\center{Table 1: Number of Unmatched Cases}
```{r extension_table_4, results = "asis"}

drops_output

```

Joining my proposed alterations with @jensenius2015development’s models results in two parameter options for matching, each with three choices, for a total of six possible combinations of replacement and caliper. Matching can either be done with or without replacement and a caliper can be 0.5, 1.62, or not applied. 

For easier reading, the six different models have been assigned the following numbering: 

Model 1: Matching without replacement | No caliper 
Model 2: Matching with replacement | No caliper 
Model 3: Matching without replacement | 0.5 caliper 
Model 4: Matching with replacement | 0.5 caliper 
Model 5: Matching without replacement | 1.62 caliper 
Model 6: Matching with replacement | 1.62 caliper

Table 2 shows the resulting covariate balance across treated and non-treated groups for each of the six matching models, compared against the pre-matching balance. For each model, two significance tests are displayed: a paired t-test and a bootstrapped Kolmogorov-Smirnov (KS) test—the same tests used by @jensenius2015development—both of which test the hypothesis that the two groups have different means. For all six models, both significance tests, and all eight covariates, there is no evidence of a significant difference between means. For some models, however, this conclusion is more robust than others. Model 2—matching with replacement and no caliper—reports the highest aggregate mean and median of t-test p-values, while Model 5—matching without replacement and a 1.62 standard deviation caliper—reports the highest aggregate of KS p-values. A higher p-value is one indication of a more statistically robust match along pre-treatment covariates. 

\center{Table 2: Difference in Means for Control and Treatment Groups}
```{r extension_table_5, results = "asis"}

balanceTable6(covariates, bal.out_norep1, bal.out_rep, bal.out_norep2, bal.out_rep_sub, 
              bal.out_norep_caliper, bal.out_rep_caliper)

```

Having verified that the covariate balance was successful, I turn to comparing the regression results. Tables 3 and 4 show the results of regressing each outcome variable of interest on treatment status after matching. For each covariate, both the direct difference and the difference in difference effect, denoted by the term “gap” is shown. These tables mirror Figure 3 from @jensenius2015development, reproduced in the appendix, to allow for an easy comparison. Most noticeably, unlike in Models 1 and 3, under which Jensenius finds no differences significant at a 5% level, here Model 4 has a 0.05 p-value for the difference coefficient of literacy rate and Model 2 has a 0.05 p-value for the difference coefficient of having a medical facility in a village. Though both of these point towards a non-null ATT, contrary to @jensenius2015development’s findings, the results should be considered with skepticism. Both barely cross the arbitrary 0.05 threshold and, given the sharp uptick in the number of regressions due to tripling the number of models being considered, it wouldn’t be surprising to find seemingly significant effects even if the ATT is null. These results should be interpreted as opening the possibility that alternate models could yield a non-null ATT, rather than independently establishing a non-null ATT. 

\pagebreak

\center{Table 3: Models 2 and 4 Treatment Regression} 
\begin{tabular}{L{2.4cm}C{4cm}C{1.7cm}C{3.2cm}}
Covariate & Before Matching & Model 2 & Model 4
\end{tabular}
```{r extension_table_6, results = "asis"}
articlematrix_output_rep
```
\pagebreak
\center{Table 4: Models 6 and 5 Treatment Regression} 
\begin{tabular}{L{2.4cm}C{4cm}C{1.7cm}C{3.2cm}}
Covariate & Before Matching & Model 6 & Model 5
\end{tabular}
```{r extension_table_7, results = "asis"}

print(articlematrix_output_cal)

```

## Conclusion

  The GoI’s non-random assignment of constituencies mandated to have SC state assembly representatives complicates the process of assessing the causal effect of SC quotas on constituency-level development indicators. Since the Delimitation Act of 1972 required reserved constituencies to be geographically spread out and located in constituencies with high proportions of SCs, @jensenius2015development augments the value of this observational data by matching treated and non-treated cases on geographic location and proportion of  SCs. 

To address the asymmetry in the number of general and reserved constituencies, Jensenius pairs treatment cases with non-treatment cases without replacement. In her first model, all pairs satisfying geographic requirements are preserved, while in her second model, a maximum distance caliper is applied, such that only pairs which are a maximum of 0.5 standard deviations of proportion of SCs apart from each other are preserved. Under both models, Jensenius fails to reject the null hypothesis that there was no constituency-level ATT on overall development, redistribution to SCs, literacy rates, SC employment patterns, or village amenities. 

I successfully replicated Jensenius’ results and failed to reject the null hypothesis using both of her models. I then proposed two changes to the matching model, resulting in four new models to assess. First, I match constituencies with replacement, so that multiple treatment cases can be paired with the same non-treatment case. Leaving all else constant, I find that matching with replacement lowers the count of unmatched treatment cases by 20% in the closest match model and by 6.9% in the caliper model. I also find a statistically significant ATT under two models at the 5% level. 

Second, I employ @wang2013optimal’s advice to optimally select a caliper value of 1.62. Holding all else constant, widening the caliper from 0.5 standard deviations to 1.62 standard deviations decreases the number of unmatched treatment cases by 66%.

Among the proposed alternate models are evidence of modifications that could result in fewer unmatched cases, better covariate balanced groups, and potentially statistically significant treatment effects. Thus, further research into the optimal choice of matching algorithm is needed. 

## Appendix 

```{r extension_table_1, results = "asis", include = FALSE}

# Optimal caliper without replacement 

balanceTable2(covariates, bal.out_norep1, bal.out_norep_caliper)

```

```{r extension_table_2, results = "asis", include = FALSE}

# Suboptimal caliper with replacement 

balanceTable2(covariates, bal.out_rep, bal.out_rep_sub)

```

```{r extension_table_3, results = "asis", include = FALSE}

# Optimal caliper with replacement 

balanceTable2(covariates, bal.out_rep, bal.out_rep_caliper)

```

```{r table_1, results = "asis", include = FALSE}

# Outputs the regression table, aligning the names of outcome variables left and
# the summary statistics right

xtable(mymatrix1, align = c("l", "r", "r", "r", "r"),
       aption = "Difference in general and SC-reserved constituencies in 2001")

```

```{r table_2, results = "asis", include = FALSE}

balanceTable2(covariates, bal.out_norep1, bal.out_norep2)

```
\center{Jensenius (2015) Table 3: Models 1 and 3 Treatment Regression} 
\begin{tabular}{L{2.4cm}C{4cm}C{1.7cm}C{3.2cm}}
Covariate & Before Matching & Model 1 & Model 3
\end{tabular}
```{r table_3, results = "asis"}

articlematrix_output

```

```{r table_4, results = "asis", include = FALSE}

table_OLS

```

```{r table_5, results = "asis", include = FALSE}

table_logit

```

```{r figure_1}

# Plotting Non-SC Population

ggplot(myplot, aes(x = x, y = y, group = group)) + 
  geom_line(aes(linetype = group, color = group)) + 
  scale_color_manual(values = c("blue", "red"), 
                     labels = c(
    paste0("General (N = ", summary(devDTA$AC_type_noST)[1], ")"), 
    paste0("Reserved (N = ", summary(devDTA$AC_type_noST)[2], ")"))) +
  scale_linetype_manual(values = c("dashed", "solid"), 
                        labels = c(
    paste0("General (N = ", summary(devDTA$AC_type_noST)[1], ")"), 
    paste0("Reserved (N = ", summary(devDTA$AC_type_noST)[2], ")"))) + 
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(face = "bold")) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.title = element_blank(), 
        legend.background = element_rect(fill = "white", color = "black", size = .5, linetype = "solid"),
        legend.justification = c(1, 0), legend.position = c(1, 0)) +
  labs(
    title = "Non-SC Population",
    x = "Year",
    y = "Literacy Rate"
  ) + 
  scale_x_continuous(breaks = c(1971, 2001)) + 
  scale_y_continuous(limits = c(10, 70),
                     breaks = c(10, 20, 30, 40, 50, 60, 70)) + 
  geom_hline(yintercept = myplot_gen[2, 1], linetype = "dotted") +
  geom_hline(yintercept = myplot_sc[1, 1], linetype = "dotted") +
  geom_line(data = myplot_arrows, arrow = arrow(length = unit(0.15, "cm"), ends = "both", type = "closed")) +
  annotate("text", x = 1971 + 2, y = myplot_gen[2, 1] - 8, 
           label = paste0("Change\ngeneral:\n", round(myplot_gen[2, 1] - myplot_gen[1, 1], 2))) + 
  annotate("text", x = 2001 - 2.5, y = myplot_sc[1, 1] + 7,
           label = paste0("Change\nreserved:\n", round(myplot_sc[2, 1] - myplot_sc[1, 1], 2)))

# Plotting SC Population

ggplot(myplot2, aes(x = x, y = y, group = group)) + 
  geom_line(aes(linetype = group, color = group)) + 
  scale_color_manual(values = c("blue", "red")) +
  scale_linetype_manual(values = c("dashed", "solid")) + 
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(face = "bold")) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        
# Removing the legend from the second plot, in line with Jensenius' choice,
# because the legend is identical from the prior graph

        legend.position = "none") +
  labs(
    title = "SC Population",
    x = "Year",
    y = "Literacy Rate"
  ) + 
  
# In-line with Jensenius, I opt to only present the tick marks for the years the
# data represents, to avoid readers interpreting the graph as commenting on the
# period between 1971 and 2001
  
  scale_x_continuous(breaks = c(1971, 2001)) + 
  scale_y_continuous(limits = c(10, 70),
                     breaks = c(10, 20, 30, 40, 50, 60, 70)) + 
  geom_hline(yintercept = myplot2_gen[2, 1], linetype = "dotted") +
  geom_hline(yintercept = myplot2_sc[1, 1], linetype = "dotted") +
  geom_line(data = myplot2_arrows, arrow = arrow(length = unit(0.15, "cm"), ends = "both", type = "closed")) +
  annotate("text", x = 1971 + 2, y = myplot2_gen[2, 1] - 8, 
           label = paste0("Change\ngeneral:\n", round(myplot2_gen[2, 1] - myplot2_gen[1, 1], 2))) + 
  annotate("text", x = 2001 - 2.5, y = myplot2_sc[1, 1] + 7,
           label = paste0("Change\nreserved:\n", round(myplot2_sc[2, 1] - myplot2_sc[1, 1], 2)))

```

```{r figure_2, include = FALSE}

# First Plot: Before Matching

ggplot() + 
  geom_density(aes(x = devDTA$SC_percent71_true[devDTA$AC_type_noST == "SC" & 
                                                  complete.cases(devDTA$AC_type_noST)], 
                   color = "Reserved")) + 
  geom_density(aes(x = devDTA$SC_percent71_true[devDTA$AC_type_noST == "GEN" & 
                                         complete.cases(devDTA$AC_type_noST)],
                   color = "General"), linetype = "dashed") +
  scale_color_manual(values = colors,
                     labels = c(paste0("General (N=" , summary(matched2$AC_type_noST)[1], ")"),
                                paste0("Reserved (N=", summary(matched2$AC_type_noST)[2], ")"))) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(face = "bold")) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.title = element_blank(), 
        legend.background = element_rect(fill = "white", color = "black", size = .5, linetype = "solid"),
        legend.justification = c(1, 0), legend.position = c(1, 0.8)) + 
  labs(x = "Percentage of SCs in Constituency",
       y = "",
       title = "Before Matching") + 
  scale_y_continuous(limits = c(0, 0.1),
                     breaks = c(0, 0.02, 0.04, 0.06, 0.08, 0.1)) +
  scale_x_continuous(breaks = c(0, 10, 20, 30, 40, 50, 60)) 


# Second Plot: After Matching

ggplot() + 
  geom_density(aes(x = matched1$SC_percent71_true[matched1$AC_type_noST == "SC"], 
                   color = "Reserved")) + 
  geom_density(aes(x = matched1$SC_percent71_true[matched1$AC_type_noST == "GEN"],
                   color = "General"), 
               linetype = "dashed") +
  scale_color_manual(values = colors,
                   labels = c(paste0("General (N=" , summary(matched2$AC_type_noST)[1], ")"),
                              paste0("Reserved (N=", summary(matched2$AC_type_noST)[2], ")"))) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(face = "bold")) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.title = element_blank(), 
        legend.background = element_rect(fill = "white", color = "black", size = .5, linetype = "solid"),
        legend.justification = c(1, 0), legend.position = c(1, 0.8)) + 
  labs(x = "Percentage of SCs in Constituency",
       y = "",
       title = "After Matching") + 
  scale_y_continuous(limits = c(0, 0.1),
                     breaks = c(0, 0.02, 0.04, 0.06, 0.08, 0.1)) +
  scale_x_continuous(breaks = c(0, 10, 20, 30, 40, 50, 60)) 

# Third Plot: After Matching with Caliper

ggplot() + 
  geom_density(aes(x = matched2$SC_percent71_true[matched2$AC_type_noST == "SC"],
                   color = "Reserved")) + 
  geom_density(aes(x = matched2$SC_percent71_true[matched2$AC_type_noST == "GEN"],
                   color = "General"), 
               linetype = "dashed") +
  scale_color_manual(values = colors,
                   labels = c(paste0("General (N=" , summary(matched2$AC_type_noST)[1], ")"),
                              paste0("Reserved (N=", summary(matched2$AC_type_noST)[2], ")"))) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(face = "bold")) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.title = element_blank(), 
        legend.background = element_rect(fill = "white", color = "black", size = .5, linetype = "solid"),
        legend.justification = c(1, 0), legend.position = c(1, 0.8)) + 
  labs(x = "Percentage of SCs in Constituency",
       y = "",
       title = "After Matching with Caliper") + 
  scale_y_continuous(limits = c(0, 0.1),
                     breaks = c(0, 0.02, 0.04, 0.06, 0.08, 0.1)) +
  scale_x_continuous(breaks = c(0, 10, 20, 30, 40, 50, 60)) 

```

```{r figure_3, include = FALSE}

ggplot(figuredf, aes(x = coefficient, y = Difference)) + 
  geom_errorbar(aes(ymax = Conf.int.min, ymin = Conf.int.max, group = type),
                  position = position_dodge(width = 0.7)) +
  geom_point(aes(shape = type),
             position = position_dodge(width = 0.7)) +
  scale_shape_manual(values = c("matching" = 19, "bias" = 17), 
                   labels = c("matching" = "Matching est.", "bias" = "Bias-adjusted est.")) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  
# I'm opting to narrow the scale on the x-axis in order to provide more detail,
# as the absolute value of no coefficient exceeds 3
  
  scale_y_continuous(limits = c(-3, 5),
                     breaks = c(-3, -2, -1, 0, 1, 2, 3)) +
  scale_x_discrete(limits = rev(levels(figuredf$coefficient))) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.title = element_blank(), 
        legend.background = element_rect(fill = "white", color = "black", size = .5, linetype = "solid"),
        legend.justification = c(1, 0), legend.position = c(1.15, 0.2),
        plot.margin = margin(10, 50, 10, 10)) +
  coord_flip() + 
  labs(
    y = "Difference in percentage points in 2001 (SC-GEN)",
    x = ""
  )

```
\pagebreak
## References